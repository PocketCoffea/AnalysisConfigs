{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 11:49:21.969322: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import spox.opset.ai.onnx.v17 as op\n",
    "from spox import argument, build, inline, Tensor\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "# from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold1.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold2.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold3.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold4.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold5.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold6.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold7.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold8.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold9.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold10.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold11.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold12.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold13.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold14.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold15.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold16.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold17.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold18.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold19.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold20.h5']\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 45)                180       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               23552     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191798 (749.21 KB)\n",
      "Trainable params: 189916 (741.86 KB)\n",
      "Non-trainable params: 1882 (7.35 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "sequential\n",
      "(None, 45)\n"
     ]
    }
   ],
   "source": [
    "main_dir='/pnfs/psi.ch/cms/trivcat/store/user/mmalucch/keras_models_morphing'\n",
    "\n",
    "#read all h5 files in the directory\n",
    "h5_files = [x for x in os.listdir(main_dir) if x.endswith('.h5')]\n",
    "print(h5_files)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(main_dir+'/'+h5_files[0])\n",
    "print(model.summary())\n",
    "print(model.name)\n",
    "print(model.input_shape)\n",
    "\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     print(layer.get_output_at(0).get_shape().as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_func=Lambda(lambda inputs: inputs[0] / inputs[1])([model.layers[-1].output[1],model.layers[-1].output[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 45) dtype=float32 (created by layer 'batch_normalization')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the ratio of the probability of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " batch_normalization_input   [(None, 45)]                 0         []                            \n",
      " (InputLayer)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 45)                   180       ['batch_normalization_input[0]\n",
      " Normalization)                                                     [0]']                         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  23552     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 512)                  2048      ['dense[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512)                  0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 256)                  1024      ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128)                  512       ['dense_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    258       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None,)                      0         ['dense_3[0][0]']             \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None,)                      0         ['dense_3[0][0]']             \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambd  (None,)                      0         ['tf.__operators__.getitem[0][\n",
      " a)                                                                 0]',                          \n",
      "                                                                     'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 191798 (749.21 KB)\n",
      "Trainable params: 189916 (741.86 KB)\n",
      "Non-trainable params: 1882 (7.35 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(None, 45)\n"
     ]
    }
   ],
   "source": [
    "#modify the model to get as output the ratio of the two classes probabilities\n",
    "# model_ratio = tf.keras.models.Model(inputs=model.input, outputs=model.layers[-1].output[1]/model.layers[-1].output[0])\n",
    "# model_ratio = tf.keras.models.Model(inputs=model.input, outputs= tf.math.divide(model.layers[-1].output[1],model.layers[-1].output[0]))\n",
    "# model_ratio = tf.keras.models.Model(inputs=model.layers[0].output, outputs= lambda_func)\n",
    "model_ratio = tf.keras.models.Model(inputs=model.input, outputs= model.output[:,1]/model.output[:,0])\n",
    "print(model_ratio.summary())\n",
    "print(model_ratio.input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# name of the input columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns =   [\"era\",\"higgs1_reco_pt\",\"higgs1_reco_eta\",\"higgs1_reco_phi\",\"higgs1_reco_mass\",\n",
    "            \"higgs2_reco_pt\",\"higgs2_reco_eta\",\"higgs2_reco_phi\",\"higgs2_reco_mass\",\n",
    "            \"HT\",\"higgs1_DeltaRjj\",\"higgs2_DeltaRjj\",\"minDeltaR_Higgjj\",\"maxDeltaR_Higgjj\",\n",
    "            \"higgs1_helicityCosTheta\",\"higgs2_helicityCosTheta\",\"hh_CosThetaStar_CS\",\n",
    "            \"hh_vec_mass\",\"hh_vec_pt\",\"hh_vec_eta\",\"hh_vec_DeltaR\",\"hh_vec_DeltaPhi\",\"hh_vec_DeltaEta\",\n",
    "            \"higgs1_reco_jet1_pt\",\"higgs1_reco_jet1_eta\",\"higgs1_reco_jet1_phi\",\"higgs1_reco_jet1_mass\",\n",
    "            \"higgs1_reco_jet2_pt\",\"higgs1_reco_jet2_eta\",\"higgs1_reco_jet2_phi\",\"higgs1_reco_jet2_mass\",\n",
    "            \"higgs2_reco_jet1_pt\",\"higgs2_reco_jet1_eta\",\"higgs2_reco_jet1_phi\",\"higgs2_reco_jet1_mass\",\n",
    "            \"higgs2_reco_jet2_pt\",\"higgs2_reco_jet2_eta\",\"higgs2_reco_jet2_phi\",\"higgs2_reco_jet2_mass\",\n",
    "            \"add_jet1pt_pt\",\"add_jet1pt_eta\",\"add_jet1pt_phi\",\"add_jet1pt_mass\",\n",
    "            \"sigma_over_higgs1_reco_mass\",\"sigma_over_higgs2_reco_mass\"]\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on fake event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 45)\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "[[0.1170899 0.8829101]]\n"
     ]
    }
   ],
   "source": [
    "# create a dummy input\n",
    "input_data = [1]+[0.01]*44\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(input_data, dtype=tf.float32)\n",
    "# add a none dimension to the input tensor\n",
    "input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "print(input_tensor.shape)\n",
    "pred = model.predict(input_tensor)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step\n",
      "[7.540446]\n"
     ]
    }
   ],
   "source": [
    "pred_ratio = model_ratio.predict(input_tensor)\n",
    "print(pred_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.540446272479523"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8829101/0.1170899"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 11:49:27.086170: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-01-29 11:49:27.086333: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-01-29 11:49:27.237769: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-01-29 11:49:27.237915: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "onnx_model,_=tf2onnx.convert.from_keras(model_ratio, input_signature=[tf.TensorSpec(shape=(None, 45), dtype=tf.float32)])\n",
    "# print(type(onnx_model), onnx_model)\n",
    "onnx.save(onnx_model, \"./model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the onnx model and test if the result is the same as for the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs name: ['args_0']\n",
      "Outputs name: ['tf.math.truediv']\n",
      "Inputs shape: [['unk__18', 45]]\n",
      "Outputs shape: [['unk__19']]\n"
     ]
    }
   ],
   "source": [
    "session = rt.InferenceSession(\n",
    "    \"./model.onnx\",\n",
    "    providers=rt.get_available_providers()\n",
    ")\n",
    "\n",
    "# print the input/putput name and shape\n",
    "input_name=[input.name for input in session.get_inputs()]\n",
    "output_name=[output.name for output in session.get_outputs()]\n",
    "print(\"Inputs name:\", input_name)\n",
    "print(\"Outputs name:\", output_name)\n",
    "\n",
    "input_shape=[input.shape for input in session.get_inputs()]\n",
    "output_shape=[output.shape for output in session.get_outputs()]\n",
    "print(\"Inputs shape:\", input_shape)\n",
    "print(\"Outputs shape:\", output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args_0': [[1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]]}\n",
      "[array([7.5404353], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input_example = {input_name[0]: [input_data]}\n",
    "print(input_example)\n",
    "\n",
    "output = session.run(output_name, input_example)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "[[9.994678e-01 5.321892e-04]]\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "[0.00053247]\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model(main_dir+'/'+h5_files[1])\n",
    "pred1 = model1.predict(input_tensor)\n",
    "print(pred1)\n",
    "model_ratio1 = tf.keras.models.Model(inputs=model1.input, outputs= model1.output[:,1]/model1.output[:,0])\n",
    "pred_ratio1 = model_ratio1.predict(input_tensor)\n",
    "print(pred_ratio1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005324725819080915"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.321892e-04/9.994678e-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 11:49:28.282802: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-01-29 11:49:28.282909: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-01-29 11:49:28.417776: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-01-29 11:49:28.417881: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "\n",
    "onnx_model1,_=tf2onnx.convert.from_keras(model_ratio1, input_signature=[tf.TensorSpec(shape=(None, 45), dtype=tf.float32)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13d060e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "[[0.811733   0.18826701]]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "[0.23193218]\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model(main_dir+'/'+h5_files[2])\n",
    "pred2 = model2.predict(input_tensor)\n",
    "print(pred2)\n",
    "model_ratio2 = tf.keras.models.Model(inputs=model2.input, outputs= model2.output[:,1]/model2.output[:,0])\n",
    "pred_ratio2 = model_ratio2.predict(input_tensor)\n",
    "print(pred_ratio2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Var from spox.internal@0::Argument->arg of float32[N][45]>\n",
      "<Var from spox.internal@0::Inline->outputs_0 of float32[?]>\n",
      "<Var from spox.internal@0::Inline->outputs_0 of float32[?]>\n"
     ]
    }
   ],
   "source": [
    "b = argument(Tensor(np.float32, ('N',45)))\n",
    "print(b)\n",
    "(r,) = inline(onnx_model)(b).values()\n",
    "(r1,) = inline(onnx_model1)(b).values()\n",
    "print(r)\n",
    "print(r1)\n",
    "\n",
    "r = op.div(op.add(r, r1), op.constant(value_float=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'onnx.onnx_ml_pb2.ModelProto'> <class 'onnx.onnx_ml_pb2.ModelProto'> <class 'onnx.onnx_ml_pb2.ModelProto'>\n"
     ]
    }
   ],
   "source": [
    "model_combine = build({'args_0': b}, {'average_w': r})\n",
    "print(type(model_combine), type(onnx_model), type(onnx_model1))\n",
    "# model_combine is a ModelProto object\n",
    "#save the model\n",
    "onnx.save(model_combine, \"./model_combine.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs name: ['args_0']\n",
      "Outputs name: ['average_w']\n",
      "Inputs shape: [['N', 45]]\n",
      "Outputs shape: [[None]]\n",
      "[array([3.770484], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "session_combine = rt.InferenceSession(\n",
    "    \"./model_combine.onnx\",\n",
    "    providers=rt.get_available_providers()\n",
    ")\n",
    "# print the input/putput name and shape\n",
    "input_name=[input.name for input in session_combine.get_inputs()]\n",
    "output_name=[output.name for output in session_combine.get_outputs()]\n",
    "print(\"Inputs name:\", input_name)\n",
    "print(\"Outputs name:\", output_name)\n",
    "\n",
    "input_shape=[input.shape for input in session_combine.get_inputs()]\n",
    "output_shape=[output.shape for output in session_combine.get_outputs()]\n",
    "print(\"Inputs shape:\", input_shape)\n",
    "print(\"Outputs shape:\", output_shape)\n",
    "\n",
    "input_example = {input_name[0]: [input_data]}\n",
    "\n",
    "output = session_combine.run(output_name, input_example)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7704892]\n",
      "[2.5909703]\n"
     ]
    }
   ],
   "source": [
    "print((pred_ratio+pred_ratio1)/2)\n",
    "print((pred_ratio+pred_ratio1+pred_ratio2)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs name: ['args_0']\n",
      "Outputs name: ['avg_w']\n",
      "Inputs shape: [['N', 45]]\n",
      "Outputs shape: [[None]]\n",
      "[array([2.5909665], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "session_combine = rt.InferenceSession(\n",
    "    main_dir+\"/average_model012.onnx\",\n",
    "    providers=rt.get_available_providers()\n",
    ")\n",
    "# print the input/putput name and shape\n",
    "input_name=[input.name for input in session_combine.get_inputs()]\n",
    "output_name=[output.name for output in session_combine.get_outputs()]\n",
    "print(\"Inputs name:\", input_name)\n",
    "print(\"Outputs name:\", output_name)\n",
    "\n",
    "input_shape=[input.shape for input in session_combine.get_inputs()]\n",
    "output_shape=[output.shape for output in session_combine.get_outputs()]\n",
    "print(\"Inputs shape:\", input_shape)\n",
    "print(\"Outputs shape:\", output_shape)\n",
    "\n",
    "input_example = {input_name[0]: [input_data]}\n",
    "\n",
    "output = session_combine.run(output_name, input_example)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
