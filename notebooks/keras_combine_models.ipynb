{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:16:53.893740: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spox.opset.ai.onnx.v17 as op\n",
    "from spox import argument, build, inline, Tensor\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "import keras\n",
    "keras.__version__\n",
    "# from keras.layers import Lambda\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold1.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold2.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold3.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold4.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold5.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold6.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold7.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold8.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold9.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold10.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold11.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold12.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold13.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold14.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold15.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold16.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold17.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold18.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold19.h5', 'model_reweightingTo4b_PASv2p0_sigmaMbbFixed_fold20.h5']\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 45)                180       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               23552     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191798 (749.21 KB)\n",
      "Trainable params: 189916 (741.86 KB)\n",
      "Non-trainable params: 1882 (7.35 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "sequential\n",
      "(None, 45)\n"
     ]
    }
   ],
   "source": [
    "main_dir='/pnfs/psi.ch/cms/trivcat/store/user/mmalucch/keras_models_morphing'\n",
    "\n",
    "#read all h5 files in the directory\n",
    "h5_files = [x for x in os.listdir(main_dir) if x.endswith('.h5')]\n",
    "print(h5_files)\n",
    "\n",
    "\n",
    "\n",
    "# model = keras.saving.load_model(main_dir+'/'+h5_files[0])\n",
    "model = tf.keras.models.load_model(main_dir+'/'+h5_files[0])\n",
    "print(model.summary())\n",
    "print(model.name)\n",
    "print(model.input_shape)\n",
    "\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     print(layer.get_output_at(0).get_shape().as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_func=Lambda(lambda inputs: inputs[0] / inputs[1])([model.layers[-1].output[1],model.layers[-1].output[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 45) dtype=float32 (created by layer 'batch_normalization')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the ratio of the probability of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " batch_normalization_input   [(None, 45)]                 0         []                            \n",
      " (InputLayer)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 45)                   180       ['batch_normalization_input[0]\n",
      " Normalization)                                                     [0]']                         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  23552     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 512)                  2048      ['dense[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512)                  0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 256)                  1024      ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128)                  512       ['dense_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    258       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None,)                      0         ['dense_3[0][0]']             \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None,)                      0         ['dense_3[0][0]']             \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambd  (None,)                      0         ['tf.__operators__.getitem[0][\n",
      " a)                                                                 0]',                          \n",
      "                                                                     'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 191798 (749.21 KB)\n",
      "Trainable params: 189916 (741.86 KB)\n",
      "Non-trainable params: 1882 (7.35 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(None, 45)\n"
     ]
    }
   ],
   "source": [
    "#modify the model to get as output the ratio of the two classes probabilities\n",
    "# model_ratio = tf.keras.models.Model(inputs=model.input, outputs=model.layers[-1].output[1]/model.layers[-1].output[0])\n",
    "# model_ratio = tf.keras.models.Model(inputs=model.input, outputs= tf.math.divide(model.layers[-1].output[1],model.layers[-1].output[0]))\n",
    "# model_ratio = tf.keras.models.Model(inputs=model.layers[0].output, outputs= lambda_func)\n",
    "model_ratio = tf.keras.models.Model(inputs=model.input, outputs= model.output[:,1]/model.output[:,0])\n",
    "print(model_ratio.summary())\n",
    "print(model_ratio.input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# name of the input columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns =   [\"era\",\"higgs1_reco_pt\",\"higgs1_reco_eta\",\"higgs1_reco_phi\",\"higgs1_reco_mass\",\n",
    "            \"higgs2_reco_pt\",\"higgs2_reco_eta\",\"higgs2_reco_phi\",\"higgs2_reco_mass\",\n",
    "            \"HT\",\"higgs1_DeltaRjj\",\"higgs2_DeltaRjj\",\"minDeltaR_Higgjj\",\"maxDeltaR_Higgjj\",\n",
    "            \"higgs1_helicityCosTheta\",\"higgs2_helicityCosTheta\",\"hh_CosThetaStar_CS\",\n",
    "            \"hh_vec_mass\",\"hh_vec_pt\",\"hh_vec_eta\",\"hh_vec_DeltaR\",\"hh_vec_DeltaPhi\",\"hh_vec_DeltaEta\",\n",
    "            \"higgs1_reco_jet1_pt\",\"higgs1_reco_jet1_eta\",\"higgs1_reco_jet1_phi\",\"higgs1_reco_jet1_mass\",\n",
    "            \"higgs1_reco_jet2_pt\",\"higgs1_reco_jet2_eta\",\"higgs1_reco_jet2_phi\",\"higgs1_reco_jet2_mass\",\n",
    "            \"higgs2_reco_jet1_pt\",\"higgs2_reco_jet1_eta\",\"higgs2_reco_jet1_phi\",\"higgs2_reco_jet1_mass\",\n",
    "            \"higgs2_reco_jet2_pt\",\"higgs2_reco_jet2_eta\",\"higgs2_reco_jet2_phi\",\"higgs2_reco_jet2_mass\",\n",
    "            \"add_jet1pt_pt\",\"add_jet1pt_eta\",\"add_jet1pt_phi\",\"add_jet1pt_mass\",\n",
    "            \"sigma_over_higgs1_reco_mass\",\"sigma_over_higgs2_reco_mass\"]\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on fake event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 255ms/step\n",
      "[[0.1170899 0.8829101]]\n"
     ]
    }
   ],
   "source": [
    "# create a dummy input\n",
    "input_data = [1]+[0.01]*44\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(input_data, dtype=tf.float32)\n",
    "# add a none dimension to the input tensor\n",
    "input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "print(input_tensor.shape)\n",
    "pred = model.predict(input_tensor)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step\n",
      "[7.540446]\n"
     ]
    }
   ],
   "source": [
    "pred_ratio = model_ratio.predict(input_tensor)\n",
    "print(pred_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.540446272479523"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8829101/0.1170899"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:05:06.456896: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-02-10 17:05:06.469569: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-02-10 17:05:06.651846: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-02-10 17:05:06.651950: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "onnx_model,_=tf2onnx.convert.from_keras(model_ratio, input_signature=[tf.TensorSpec(shape=(None, 45), dtype=tf.float32)])\n",
    "# print(type(onnx_model), onnx_model)\n",
    "onnx.save(onnx_model, \"./model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the onnx model and test if the result is the same as for the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs name: ['args_0']\n",
      "Outputs name: ['tf.math.truediv']\n",
      "Inputs shape: [['unk__18', 45]]\n",
      "Outputs shape: [['unk__19']]\n"
     ]
    }
   ],
   "source": [
    "session = rt.InferenceSession(\n",
    "    \"./model.onnx\",\n",
    "    providers=rt.get_available_providers()\n",
    ")\n",
    "\n",
    "# print the input/putput name and shape\n",
    "input_name=[input.name for input in session.get_inputs()]\n",
    "output_name=[output.name for output in session.get_outputs()]\n",
    "print(\"Inputs name:\", input_name)\n",
    "print(\"Outputs name:\", output_name)\n",
    "\n",
    "input_shape=[input.shape for input in session.get_inputs()]\n",
    "output_shape=[output.shape for output in session.get_outputs()]\n",
    "print(\"Inputs shape:\", input_shape)\n",
    "print(\"Outputs shape:\", output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args_0': [[1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]]}\n",
      "[array([7.5404353], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input_example = {input_name[0]: [input_data]}\n",
    "print(input_example)\n",
    "\n",
    "output = session.run(output_name, input_example)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n",
      "[[9.994678e-01 5.321892e-04]]\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "[0.00053247]\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model(main_dir+'/'+h5_files[1])\n",
    "pred1 = model1.predict(input_tensor)\n",
    "print(pred1)\n",
    "model_ratio1 = tf.keras.models.Model(inputs=model1.input, outputs= model1.output[:,1]/model1.output[:,0])\n",
    "pred_ratio1 = model_ratio1.predict(input_tensor)\n",
    "print(pred_ratio1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005324725819080915"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.321892e-04/9.994678e-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:05:09.241585: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-02-10 17:05:09.241679: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-02-10 17:05:09.359456: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-02-10 17:05:09.359539: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "\n",
    "onnx_model1,_=tf2onnx.convert.from_keras(model_ratio1, input_signature=[tf.TensorSpec(shape=(None, 45), dtype=tf.float32)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f092c15c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "[[0.811733   0.18826701]]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f092c15c160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "[0.23193218]\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model(main_dir+'/'+h5_files[2])\n",
    "pred2 = model2.predict(input_tensor)\n",
    "print(pred2)\n",
    "model_ratio2 = tf.keras.models.Model(inputs=model2.input, outputs= model2.output[:,1]/model2.output[:,0])\n",
    "pred_ratio2 = model_ratio2.predict(input_tensor)\n",
    "print(pred_ratio2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Var from spox.internal@0::Argument->arg of float32[N][45]>\n",
      "<Var from spox.internal@0::Inline->outputs_0 of float32[?]>\n",
      "<Var from spox.internal@0::Inline->outputs_0 of float32[?]>\n"
     ]
    }
   ],
   "source": [
    "b = argument(Tensor(np.float32, ('N',45)))\n",
    "print(b)\n",
    "(r,) = inline(onnx_model)(b).values()\n",
    "(r1,) = inline(onnx_model1)(b).values()\n",
    "print(r)\n",
    "print(r1)\n",
    "\n",
    "r = op.div(op.add(r, r1), op.constant(value_float=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'onnx.onnx_ml_pb2.ModelProto'> <class 'onnx.onnx_ml_pb2.ModelProto'> <class 'onnx.onnx_ml_pb2.ModelProto'>\n"
     ]
    }
   ],
   "source": [
    "model_combine = build({'args_0': b}, {'average_w': r})\n",
    "print(type(model_combine), type(onnx_model), type(onnx_model1))\n",
    "# model_combine is a ModelProto object\n",
    "#save the model\n",
    "onnx.save(model_combine, \"./model_combine.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs name: ['args_0']\n",
      "Outputs name: ['average_w']\n",
      "Inputs shape: [['N', 45]]\n",
      "Outputs shape: [[None]]\n",
      "[array([3.770484], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "session_combine = rt.InferenceSession(\n",
    "    \"./model_combine.onnx\",\n",
    "    providers=rt.get_available_providers()\n",
    ")\n",
    "# print the input/putput name and shape\n",
    "input_name=[input.name for input in session_combine.get_inputs()]\n",
    "output_name=[output.name for output in session_combine.get_outputs()]\n",
    "print(\"Inputs name:\", input_name)\n",
    "print(\"Outputs name:\", output_name)\n",
    "\n",
    "input_shape=[input.shape for input in session_combine.get_inputs()]\n",
    "output_shape=[output.shape for output in session_combine.get_outputs()]\n",
    "print(\"Inputs shape:\", input_shape)\n",
    "print(\"Outputs shape:\", output_shape)\n",
    "\n",
    "input_example = {input_name[0]: [input_data]}\n",
    "\n",
    "output = session_combine.run(output_name, input_example)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7704892]\n",
      "[2.5909703]\n"
     ]
    }
   ],
   "source": [
    "print((pred_ratio+pred_ratio1)/2)\n",
    "print((pred_ratio+pred_ratio1+pred_ratio2)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs name: ['args_0']\n",
      "Outputs name: ['avg_w']\n",
      "Inputs shape: [['N', 45]]\n",
      "Outputs shape: [[None]]\n",
      "[array([2.5909665], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "session_combine = rt.InferenceSession(\n",
    "    main_dir+\"/average_model012.onnx\",\n",
    "    providers=rt.get_available_providers()\n",
    ")\n",
    "# print the input/putput name and shape\n",
    "input_name=[input.name for input in session_combine.get_inputs()]\n",
    "output_name=[output.name for output in session_combine.get_outputs()]\n",
    "print(\"Inputs name:\", input_name)\n",
    "print(\"Outputs name:\", output_name)\n",
    "\n",
    "input_shape=[input.shape for input in session_combine.get_inputs()]\n",
    "output_shape=[output.shape for output in session_combine.get_outputs()]\n",
    "print(\"Inputs shape:\", input_shape)\n",
    "print(\"Outputs shape:\", output_shape)\n",
    "\n",
    "input_example = {input_name[0]: [input_data]}\n",
    "\n",
    "output = session_combine.run(output_name, input_example)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
